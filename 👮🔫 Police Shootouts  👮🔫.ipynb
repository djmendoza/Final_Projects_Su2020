{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final_Projects_Su2020\n",
    "**IS590PR** Summer 2020 \n",
    "**Author**: David Mendoza\n",
    "**GitHub ID**: djmendoza\n",
    "**Fork URL**: https://github.com/djmendoza/Final_Projects_Su2020\n",
    "\n",
    "---\n",
    "\n",
    "## Type III Project Introduction\n",
    "\n",
    "Since 2015, The Washington Post (\"The Post\") has been building a database of fatal police shootings in the United States,\n",
    "along with pertinent information relating to each incident (e.g., race of participants , gender, body-cams,\n",
    "if the deceased was suffering a mental-health crisis, etc.).\n",
    "According to The Post, their dataset is nearly twice the size as the official FBI dataset on the same subject, due in part to varied reporting\n",
    "practices among policing agencies, as well as other factors, and notes, \"5480 people have been shot and killed by police since Jan. 1, 2015\" (Tate et al., 2015).\n",
    "\n",
    "The Post recently released this dataset has recently become available for public use, and the kernel I will be reviewing and enhancing was the top-rated kernel based\n",
    "on the data in the first weeks of the database's release. A legacy copy, as well as my annotated review copy, is included in this GitHub Repo.  \n",
    "Mrinaal007's kernel uses Numpy and Pandas, as well as visualization/plotting modules (e.g., matplotlib, seaborn).\n",
    "\n",
    "### The Type III review will cover 3 areas relating to the project:\n",
    "\n",
    "1. Project Code Review: A detailed review of user Mrinaal007's kernal notebook based on John Weible's *Program Quality and Code Reviews* (Weible, 2020) featuring some analysis.\n",
    "2. Kaggel Project Analysis Review: An detailed analysis of one of the sections of the project, featuring an enhancement.\n",
    "3. Fatal Force Database Analysis: A brief analysis of racial categories in the Washington Post's *Fatal Force* database. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### *Note: The cells below are the work of the original developer Mrinal (mrinaal007 (alias), 2020), and are functionally untouched from the developer's (now defunct) Kaggel notebook, save for line sections denoted by double ##'s and comments, such as in Section 2.* \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='one'>1. Importing Libaries </a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import missingno as msno\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='two'>2. Loading the data & basic pre-EDA</a>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'fatal-police-shootings-data.csv' does not exist: b'fatal-police-shootings-data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b2ae9ccc4997>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m##df = pd.read_csv('/kaggle/input/data-police-shootings/fatal-police-shootings-data.csv')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fatal-police-shootings-data.csv'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m## changed file location  to my own github for ease of use\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'fatal-police-shootings-data.csv' does not exist: b'fatal-police-shootings-data.csv'"
     ]
    }
   ],
   "source": [
    "##df = pd.read_csv('/kaggle/input/data-police-shootings/fatal-police-shootings-data.csv')\n",
    "df = pd.read_csv('fatal-police-shootings-data.csv') ## changed file location  to my own github for ease of use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='three'>3. Datetime Feature Engineering</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df['month'] = pd.to_datetime(df['date']).dt.month\n",
    "df['year'] = pd.to_datetime(df['date']).dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='four'>4. Missing Values</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "msno.matrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentage of missing values\n",
    ">### Since missing values are less than 5% for almost all the data. Therefore, By dropping missing records we aren't loosing lot of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing_percentage=df.isna().sum()*100/df.shape[0]\n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking cardinality of the features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "cardinality ={}\n",
    "for col in df.columns:\n",
    "    cardinality[col] = df[col].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df['race'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='five'>5. Distribution of shootouts by the police 👮</a>\n",
    ">### From the distribution,It seems like that White american were shot by the police most often during police engagement.\n",
    ">### In the data, acronymns used and their meanings:\n",
    "\n",
    ">A - Asian,\n",
    "W - White,\n",
    "H - Hispanic,\n",
    "B - Black,\n",
    "O - Others,\n",
    "N - Native\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "killing_by_race=df[df['manner_of_death']=='shot']\n",
    "fig = px.histogram(killing_by_race,x='race',color='race')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='six'>6. Distribution of unarmed people killed due to police shootout across different race</a>\n",
    "\n",
    "> ### It is evident from the graph that among unarmed people white people were killed the most followed by the black people "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "unarmed_shootout = df[df['armed']=='unarmed']['race']\n",
    "fig = px.histogram(unarmed_shootout,x='race',color='race')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='seven'>7. Top 10 states in the US infamous for police shootings</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "shootout_by_states = df['state'].value_counts()[:10]\n",
    "shootout_by_states = pd.DataFrame(shootout_by_states)\n",
    "shootout_by_states=shootout_by_states.reset_index()\n",
    "fig = px.pie(shootout_by_states, values='state', names='index', color_discrete_sequence=px.colors.sequential.RdBu)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='eight'>8. Agewise distribution of the people who were shot</a>\n",
    "\n",
    "\n",
    "> ### From the graph, most of the people who were shot were between late twenties and early thirties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "np.random.seed(1)\n",
    "x = df['age']\n",
    "hist_data = [x]\n",
    "group_labels = ['Age']\n",
    "fig = ff.create_distplot(hist_data, group_labels)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='nine'>9. Usage of Body Camera</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Majority of the time police was not using body camera!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df['body_camera'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Racewise summary of the shootouts when police wasn't using body camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "camera_false = df[df['body_camera']==False]\n",
    "camera_false['race'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Racewise summary of the shootouts when police was using body camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "camera_true = df[df['body_camera']==True]\n",
    "camera_true['race'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='ten'>10. Daywise distribution of shootings</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "daily_shootouts = df[['date']]\n",
    "daily_shootouts['kills'] = 1\n",
    "daily_shootouts=daily_shootouts.groupby('date').sum()\n",
    "daily_shootouts = daily_shootouts.reset_index()\n",
    "\n",
    "fig = px.line(daily_shootouts, x='date', y='kills')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='eleven'>11. Innocent people shot by police</a>\n",
    "> ### People who were shot by the police who didn't have any signs of mental illness nor they were armed or fleeing from the police."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "innocent_people = df[(df.signs_of_mental_illness==False) & (df.armed =='unarmed') & (df.flee=='Not fleeing')]\n",
    "innocent_people = innocent_people['race'].value_counts()\n",
    "innocent_people = pd.DataFrame(innocent_people)\n",
    "innocent_people=  innocent_people.reset_index()\n",
    "fig = px.pie(innocent_people, values='race', names='index', color_discrete_sequence=px.colors.sequential.RdBu)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='twelve'>12. Yearwise shooting by Police</a>\n",
    "> ### Around 825 people are shot by US Police on an average throughout the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "yearly_shootouts = df['year'].value_counts()\n",
    "yearly_shootouts = pd.DataFrame(yearly_shootouts)\n",
    "yearly_shootouts= yearly_shootouts.reset_index()\n",
    "yearly_shootouts=yearly_shootouts.rename(columns={'index':'year','year':'Shootouts'})\n",
    "fig = px.bar(yearly_shootouts, y='Shootouts', x='year', barmode='group')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='thirteen'>13. Yearwise shooting by Police - Racewise</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "kills_per_year = df[['year','race']]\n",
    "kills_per_year ['kills'] =1\n",
    "kills_per_year  = kills_per_year .groupby(['year','race']).sum()\n",
    "kills_per_year = kills_per_year .reset_index()\n",
    "fig = px.bar(kills_per_year , y='kills', x='year',color='race', barmode='group')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='fourteen'>14. Monthwise shooting by Police - Racewise</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "kills_monthly = df[['month','race']]\n",
    "kills_monthly['kills'] =1\n",
    "kills_monthly  = kills_monthly.groupby(['month','race']).sum()\n",
    "kills_monthly =  kills_monthly.reset_index()\n",
    "fig = px.bar(kills_monthly, y='kills', x='month',color='race', barmode='group')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='fifteen'>15. Mental illness and Shooting across different race</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "mental_illness = df[df.signs_of_mental_illness==True]\n",
    "mental_illness = mental_illness[['year','race']]\n",
    "mental_illness['kills'] =1\n",
    "mental_illness  = mental_illness.groupby(['year','race']).sum()\n",
    "mental_illness= mental_illness.reset_index()\n",
    "fig = px.bar(mental_illness, y='kills', x='year',color='race', barmode='group')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='sixteen'>16. City with most police killing (Yearwise) </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "yearly_shooting_record_citywise = df[['city','year']]\n",
    "yearly_shooting_record_citywise['kills'] = 1\n",
    "yearly_shooting_record_citywise = yearly_shooting_record_citywise.groupby(['year','city']).sum()\n",
    "yearly_shooting_record_citywise= yearly_shooting_record_citywise.reset_index()\n",
    "yearly_shooting_record_citywise=yearly_shooting_record_citywise.sort_values(by=['year','kills'],ascending=False)\n",
    "yearly_shooting_record_citywise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "city_shooting= pd.DataFrame(columns=['year','city','kills'])\n",
    "for year in range(2015,2021):\n",
    "    temp= yearly_shooting_record_citywise[yearly_shooting_record_citywise.year==year].iloc[0:1,:]\n",
    "    city_shooting=city_shooting.append(temp,ignore_index=True)\n",
    "\n",
    "fig = px.bar(city_shooting, y='kills', x='year',color='city', barmode='group')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='seventeen'>17. Statewise killing across different years with/without Body Camera</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "sns.catplot(x = 'year',y='state', kind = 'box', data = df,height = 10, col = 'body_camera')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # <a id='eighteen'>18. Conclusion</a>\n",
    " >### From the whole analysis, It is consistent that whites are more likely to get shot by the police followed by the blacks. \n",
    " \n",
    " >## Thank you so much! Please **upvote** if you found the analysis interesting, It keeps me motivated for delivering quality content! \n",
    " <img src='https://media.giphy.com/media/9Ai5dIk8xvBm0/giphy.gif' height=500 width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a href='#Top'><button>Go to Top</button></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "------\n",
    "\n",
    "### *Note: The preceding cells are the work of the original developer Mrinal, and are functionally untouched from the developer's (now defunct) Kaggel notebook, save for line sections denoted by double ##'s and comments, such as section 2. All cells below are the original comments and work of UIUC student davidjm8 (a.k.a. djmendoza) for IS 590PR SU2020, except where noted.*\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " immediate threat to life## IS590 PR Final Project Written Analysis\n",
    "\n",
    "### Project Background\n",
    "\n",
    "User Mrinal's Kaggle kernel entitled *👮🔫 Police Shootouts 👮🔫* explores the Washington Post's *\"Fatal Force\"* police shooting database, and it features some competent use of Pandas and Numpy; it is both well laid-out and easy to follow, making navigation of its notebook simple and intuitive though the use of a convenient table-of-contents. Likewise, as presented, most of the sections that are covered appear to feature succinct code that pulls data straight from the dataframe, being therefore both straight-forward and matter-of-fact, used principally to select desired portions of the dataframe and then present said sections via various plotting methods. The chosen plotting methods appear to be succinct and easily understandable without the need for extensive explanation (perhaps with the exception of *4. Missing Values*).\n",
    "\n",
    "*A note on section titles: Mrinal has decided to liberally use emojis throughout the text their project; for readability, outside of the reference to the title above or direct quotes, I will dispense with including these emojis when referring to sections titles throughout the course of my analysis.*  \n",
    "\n",
    "---\n",
    "\n",
    "### Database Components\n",
    "\n",
    "The *Washington Post's* *Fatal Force* database is a collection of fatal United States police shooting data from 2015 until the present. It is in csv format, and features the following headings:\n",
    "\n",
    "* **id**\n",
    "* **name**  - The suspect/victim's name\n",
    "* **date** (yyyy-mm-dd format)\n",
    "* **manner_of_death** -  *Shot, Tasered*, or \"*shot and Tasered*\"\n",
    "* **armed** - *unarmed, gun, toy gun, knife, NaN*, as well as others (e.g. *shovel*) \n",
    "* **age** (float64)\n",
    "* **race** - the suspect/victim's race (in a questionable format to be addressed later)\n",
    "* **gender** - *male, female, None* (i.e., unknown)\n",
    "* **city**\n",
    "* **state**\n",
    "* **signs_of_mental_illness** (bool)\n",
    "* **threat_level** - *attack, undetermined, other*:\n",
    "    * *attack*: Highest level, officer considered deceased an \"immediate threat to life\" (The Post, 2018); includes weapons use \n",
    "    * *other*: \"Other includes many incidents where officers or others faced significant threats\" (The Post, 2018)\n",
    "    * *undetermined*\n",
    "  \n",
    "* **fleeing** - *Not fleeing, Car, Foot, NaN*:\n",
    " Was the deceased fleeing at the time of the shooting? This is independent of **threat_level**, and should not imply lack of aggression\n",
    "* **body_camera** - Was there police body camera footage of the data available\n",
    "\n",
    "### Race variables\n",
    "\n",
    "According to the Post's GitHub (2015), the racial categories are:\n",
    "\n",
    "* W: White, non-Hispanic\n",
    "* B: Black, non-Hispanic\n",
    "* A: Asian\n",
    "* N: Native American\n",
    "* H: Hispanic\n",
    "* O: Other\n",
    "* None: unknown\n",
    "\n",
    "The implications of this choice of racial breakdowns will be discussed later in an analysis of the *Fatal Force* database itself.\n",
    "\n",
    "----\n",
    "\n",
    "## Project Code Review\n",
    "\n",
    "The 👮🔫 Police Shootouts  👮🔫 kernel notebook is well-organized and succinct, even though it covers a number of varied aspect of data exploration (e.g., age, race,  body-camera usage, distribution of unarmed suspects/victims, etc). Likewise, the notebook uses interesting and varied plotting methods to readily articulate the data, including histograms and pie-charts, among others, and maintains a logical progression of the data analysis. However, there are some rather questionable issues in the language and assumptions used in the code that denote a bias in the user's approach (especially in regards to what constitutes an \"innocent\" suspect/victim vis-a-vis one who is not \"innocent\").\n",
    "Similarly, confusing choices for variables and section titles paired with a lack of in-line comments, introduces ambiguity to one's ability to engage with the content on offer, as will be discussed further.\n",
    "\n",
    "This Kaggle kernel principally serves as a quickly-assembled exploration into the *Fatal Force* database, and, as such, does not feature many conventions of coding style that one would assume from a more fully-developed or complete project (e.g., Doctests, adequate or frequent coding comments, modularity through use of functions, etc.). For example, despite a clear interface, the code does not feature any end-user instructions for loading the database or porting the kernel to other platforms, nor does it feature exception handling or error feedback to the user; likewise, this kernel presumes its users have familiarity with Pandas and Numpy, and mostly ignores providing detailed explanations of most of the data points being extracted. However, as the kernel is both straight-forward and aimed at an audience of other Kaggle users for use on Kaggle's website, it is not particularly necessary for the program to feature detailed end-user instructions, as it serves its purpose on Kaggle adequately (however, I would be remiss to ignore that I did need to adjust the `pd.read_csv()` file location in order to operate own copy included here). Similarly, modularity is not a feature of this Kaggle kernel, as the kernel features no functions and is hard-coded for direct manipulation of the data straight from the dataframe. Again, whether this is necessarily to the detriment of the kernel is debatable, as, like noted earlier, the kernel is aimed at being a quick overview and its current format is both utilitarian and aimed at providing quick plotting for ready digestion of said data. \n",
    "\n",
    "\n",
    "#### **Program Behavior, Usability, Design** (Weible, 2020, p.1)\n",
    "\n",
    "There is only one dataset in use by the notebook, `fatal-police-shootings-data.csv`, which appears to be loaded from the original Kaggle page hosted for this data set owned by user [Andriy Samoshin](https://www.kaggle.com/mrmorj/data-police-shootings/notebooks?sortBy=hotness&group=everyone&pageSize=20&datasetId=723010). However, it may be loaded from the user Mrinal's own Kaggle repo; regardless, while the legitimacy of the dataset is taken on good-faith to be unaltered and not 'tainted' from its original Washington Post GitHub, technically, this may be an area where \"untrusted external input\" (p.1) could be introduced to the notebook, and appears outside the author's direct control as written. However, as accessing this public data is basically the point of the kernel/shared dataset/Kaggle, that is not really a major point against the it (as previously noted, for ease of use, I did change my version's `read_csv()` path to point to a local copy).\n",
    "\n",
    "What is somewhat ethically ambiguous that the code features no citations or supporting materials for the code used; it is possible that the author did create the code on offer extemporaneously (as it is not particularly complex for someone of a skillset greater than my ken), but Mrinal's does not reference any code for any of the modules used. I do know that their notebook was one of the earliest published for this newly released dataset, however, so Mrinal is one of the first Kaggle users to work with the `fatal-police-shootings-data.csv`, and likely is using their own work. However, as the documentation fails to provide any citations to other work, this can only be presumed as opposed to explicitly demonstraited.   \n",
    "\n",
    "#### **Modularity & Reusability** (2020, p.2)\n",
    "\n",
    "**Is the code written in an overly-specific way that prevents it from being re-usable?**\n",
    "\n",
    "Yes, though whether this is inappropriate is debatable? As the code is designed to manipulate, extract, and plot data from one specific database (i.e., *Fatal Force*), it is insular and specific to the that single database. This may be acceptable, however, as the program does have clear division between the categories of the notebook sections, and each are easily marked and readily understood; each section has only a few snippets of code chunks, allowing one to understand the code of each category independently, meaning the code is more utilitarian than \"fully-formed\", but this is not really to the detriment of the program's usability as much as it is a limitation of modularity in applying the code as-written to other datasets: *limited modularity is a given here as it is working with a single dataframe for one dataset*.\n",
    "\n",
    "For example, in section *5. Distribution of shootouts by the police*, with `px` meaning the `plotly.express` module, Mrinal's code reads:\n",
    "\n",
    "    killing_by_race=df[df['manner_of_death']=='shot']\n",
    "    fig = px.histogram(killing_by_race,x='race',color='race')\n",
    "    fig.show()\n",
    "\n",
    "Naturally, as this code is a query designed to pull and plot specific data from a singular dataset, it is not particularly flexible in what ways it may be utilized, but as three lines of code, it certainly accomplishes its task succinctly.\n",
    "\n",
    "Still, the code lacks functions, classes, and other typical aspects associated with more robust coding conventions; it is, at its core, a collection of short code-chucks strung together by a single dataframe and theme. Were it to incorporate an additional outside dataset, there would undoubtedly need to be some revisions to the code in order to accommodate.\n",
    "\n",
    "#### Efficiency (p.2)\n",
    "\n",
    "**Is the code written efficiently and does the code perform efficiently** (2020, p.2)?\n",
    "\n",
    "I  believe so, yes, with a few exceptions. The code is certainly succinct. It is minimal, but it extracts the desired data and then plots said data as desired. Likewise, the code is minimal enough that there is no perceived slow-down in running the code. The original notebook is hosted on Kaggle, but running the code on a local system only results in a limited initial hang-up of resources (likely just a result of the Juptyer notebook initializing), but any additional reimplementation of the code results in near-instantaneous results (not  surprising given the minimal lines used per category). There has been a few issues with the code that I will address in the next section that does relate to running the code with Jupyter Notebooks.\n",
    "\n",
    "The one area that could be considered inefficient in that, while the developer does check for `dtypes` on import of the dataframe, they do not specify any particular typing for the data, leaving it up to Python. Most of the data are set as objects, but could likely be changed into strings. \n",
    "\n",
    "**Professional-Quality & Production-Quality Considerations** (2020, p.2)\n",
    "\n",
    "The kernel does not feature any bug or issue-tracking systems, nor does feature any VCS commits that I was able to to find (though Kaggle does link to both GitHub and/or Google's Developer API, so they may be hidden elsewhere).\n",
    "\n",
    "I have encountered a continued issue with the graph in *10. Daywise distribution of shootings* failing to render in Pycharm, but it does not have an issue rendering within Jupyter Notebooks, so this may be specific to my PC or PyCharm, respectively. As for running on Juptyer Notebooks, I have experienced a few troubles with most of the plotted cells not rendering the first time the program is run, but a \"Restart & Clear Output\" action seems to clear the issue up and post as expected. Regardless, this code kernel is not designed to be robust, but does feature multi-OS capabilities, as it is a Jupyter Notebook kernel.\n",
    "\n",
    "Interestingly, at *4. Missing Values*, the developer used a check, output, and plot the missing values in the dataset.\n",
    "Then developer uses `df.dropna()` to scrub out the NA values. I am curious if this best practice when dealing with these types of missing data; in section 4, the developer claims, \"Since missing values are less than 5% for almost all the data.\\[*sic*\\] Therefore, By \\[*sic*\\] dropping missing records we aren't loosing \\[*sic*\\] lot of information\". 5% seems like a lot of missing data to just ignore to me as is, but the racical data seems to be at almost 10%.   \n",
    "\n",
    "#### **Maintainability & Readability** (Weible, 2020, p.1)\n",
    "\n",
    "If there is an area that the the short program encounters real issues, it is in its readability, and some of the issues discussed here will lead into the analysis of the later critique of the implications of the Mrinal's data analysis.\n",
    "\n",
    "*First, an aside:*  To be candid, I found the user's choice to begin and end the notebook with animated gifs (*South Park* and *Mr. Bean*, respectively) to be in poor taste. I am not overly familiar with Kaggle's atmosphere, but it does appear to be casual and light-hearted across the site, which is good and inviting in itself. However, the subject matter of database in question is a collection of **the sudden and violent deaths of human persons** (as well as possible subsequent psychological trauma on the part of the officers involved), so perhaps gravitas would be more appropriate in dealing with it here.\n",
    "\n",
    "Regardless, as previously noted, as far as I can tell, there is no stable VSC or commit record available for this program available, so I am unable to comment on that (they may have even created it in one session). That said, the code style does appear to be consitent througout the notebook, and does appear to be styled correctly for its purpose and genre (i.e., Pandas queries). My familiarity with plotting functions is limited, but a cursory look into the documentation on matplot and plotly seems to indicate acceptable usage here (not suprising, again, given the program's utilitarian scripting)(Bar Charts | Python | Plotly, 2020; Hunter et al., 2020; NetworkX Developers, 2019).    \n",
    "\n",
    "However, the developer's choices for section titles and variables are often confusing and questionably accurate. For example, *6. Distribution of unarmed people killed due to police shootout across different race* features the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from (Mathieu, 2017), https://gitlab.com/gitlab-org/gitlab-foss/-/issues/33995, due to GitHub Markdown limitations\n",
    "from IPython.display import display, Image\n",
    "display(Image(filename='screenshots/6.Distribution.PNG'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The developer chose to use the variable `unarmed_shootout`, which is confusing for a few reasons:\n",
    "\n",
    "* It is not really properly descriptive in a coding sense (i.e., it is not descriptive of the data that it contains). `unarmed_shootout` does indeed feature the data of shootings where the deceased was unarmed, but its query is also *sorted by race*, so wouldn't describing that be useful to note?\n",
    "`unarmed_shootout_by_race` or `unarmed_shootout_race` might be more clear.\n",
    " For reference, `unarmed_shootout.tail()` looks like so:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename='screenshots/6.Tail.PNG'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It is not really properly descriptive in a logical sense (i.e., it is not descriptive of what the data is *telling us*).\n",
    "A shootout in which one of the participants is unarmed is not a \"shootout\", it is a \"shooting\". A \"shootout\" implies that at least two participants are exchanging fire with each other. \n",
    "\n",
    "This second point is one of the more curious aspects of the whole notebook/kernel. The developer uses the term \"shootout\" throughout the whole of the project (even in the title), but such a term is not really reflective of the overall dataset, which only features ~2600 instances where a \"shootout\" could occur (not that a shootout actually *did* occur, just that there was a potential for one to, as the deceased was in possession of a firearm at the time of the incident): \n",
    "\n",
    "*Note: The following code is adapted from* (Guan, 2020a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code adaped (Guan,Y 2020a), https://github.com/iSchool-590pr/Summer2020_examples/blob/master/week_08_pandas/pandas_intro.ipynb \n",
    "# These queries ignore the variables 'knive', 'toy gun', and all others. \n",
    "unarmed_shooting = df[df['armed']=='unarmed'].shape[0]\n",
    "armed_shooting_gun = df[df['armed']=='gun'].shape[0]\n",
    "print('The # of unarmed shootings was', unarmed_shooting, 'versus the # of armed shootings (gun), at',armed_shooting_gun, \".\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program also features other language issues that cause confusion, but I suspect that is is a product of the developer not being a native English speaker, which, of course, is no fault of their own, but it does highlight the issue of others being able to understand your code or what you are trying to convey with your data analysis. Again, this is just a Kaggle Exploritory Analysis notebook, not a school assignment or professional program, but it would certainly require grammatical editing to conform to American Business English standards if it was. Ultimately, however, the code *itself* is easily understood and does not require much revision; it is surrounding commentary and variable names that would need to be addressed. Such issues would not likely be too problematic, but they begin to bleed into the developer's analysis of the data as well, which hurts the credibility of their findings, as will be discussed next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Kaggel Project Analysis Review\n",
    "\n",
    "**Unfortunate Implications of Language**\n",
    "\n",
    "*I assert that, when producing something that may be consumed by others, it is an ethical responsiblity to be cautious and sensitive to both the subject matter at hand, as well as one's audience. I believe this certainly extends to development, both in the code created and the results produced.* Unfortunately, some of the choices and results of this Kaggel kernel made me very uncomfortable. \n",
    "\n",
    "\n",
    "The kernal's analysis has been influenced by the earlier inacurrate use of language. The most glaring of these analytical oversites (in my opinion) regards the discussion in *11. Innocent people shot by police*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename='screenshots/11.Full.PNG'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From an analysis point of view, for example, \"11. Innocent people shot by police\" indicates a flaw in an understanding of the topic as a whole\n",
    "(or, at least an ambiguity that could be taken as either biased or insensitive), as the delineation between \"innocent\"\n",
    "and whatever its opposite is circumspect:\n",
    "\"People who were shot by the police who didn't have any signs of mental illness nor they were armed or fleeing from the police\".\n",
    "\n",
    "Because of a commonly known aspect of United States criminal law, as none of the deceased individuals were convicted as guilty in a court of law over the incidents for which they were shot, they are, under the United States Pesumption of Innocence tenent (along with due process requirements), *presumptively* not guilty based on the fact that the desceased have not been found as guilty under due process requirements mandated in the Fifth and Fourteenth Amendments of the United States Constitution (The Constitution of the United States and The Declaration of Independence, 2016). Naturally, just because one is **unable to be found guilty** does not necessitate that one is **innocent**. Ignoring the likely relevant point that the developer may not be overly familiar with United States criminal law, the choice of the queries still strikes me as bizarre:\n",
    "\n",
    "    innocent_people = df[(df.signs_of_mental_illness==False) & (df.armed =='unarmed') & (df.flee=='Not fleeing')]\n",
    "\n",
    "It may be more accurate to denote these were cases where there was no 'justifiable use of force',\n",
    "but, due to the developer's particular query choses, that would still indicate that lethal use of force is justifiable against the mentally-distressed or those those who were fleeing from police, which is a position that I assume many would find untenable and/or outright offensive. One could even argue that a mental-health crisis a may negate someone's guilt in an altercation, as one's agency may be nullified by said mental-distress, therefore negating one's complicity therein. \n",
    "The query also infers \"armed\" == \"illegal possession\", which is presumptive for those living in a nation known for its legally enshrined right-to-bear arms (2016, p.25). Similarly, `(df.armed =='unarmed')` ignores cases where the object held by the desceased may be inoccuous (e.g., toy gun, shovel, etc.), but might cause an (arguable) over-reaction on the part of the officers or where, in context not provided by this database, a response may be reasonable considered justifiable (i.e., if the deceased was attacking a third-party or the officers with impunity). More to this, \"unarmed\" in no way implies a lack of aggression or ability to main or kill. \n",
    "\n",
    "I do not think this these blind-spots were part of the developer's intention, but I state that primarily out of a courtesy to assume the positive intent of the other. Taken by itself, the query language certainly indicates an intentionality behind these choices, and therefore a clear oversite or possible bias. Regardless, it is ambiguous enough to be an issue, especially given how developer's possible bias is built into the code itself via the query language used. For my own part, I have chosen to use the term *deceased* to describe the individuals in the database, as it is both neutral and accurate, **though I am unsure if it is the best or most sensitive option, either**.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correcting This Issue** (IN PROGRESS)\n",
    "\n",
    "\n",
    "As the data has a variable that accounts for the threat level, including it in a query relating to some type of presumed justified use of force on the part of the officer may be a prundent step. According to [The Post's GitHub (2018)](https://github.com/washingtonpost/data-police-shootings): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The threat_level column was used to flag incidents for the story by Amy Brittain in October 2015. http://www.washingtonpost.com/sf/investigative/2015/10/24/on-duty-under-fire/ As described in the story, the general criteria for the attack label was that there was the most direct and immediate threat to life. That would include incidents where officers or others were shot at, threatened with a gun, attacked with other weapons or physical force, etc. The attack category is meant to flag the highest level of threat. The other and undetermined categories represent all remaining cases. Other includes many incidents where officers or others faced significant threats (para. 8).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reference\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is helps in understanding some of what `threat_level` constitutes, but `other` is so vague as to be as ambigious as `undetermined`.\n",
    "Likewise, in the Post's (2018) otherwise bare-bones GitHub, they explains that, \"The threat column and the fleeing column are not necessarily related\", and note the above [article](http://www.washingtonpost.com/sf/investigative/2015/10/24/on-duty-under-fire/) as an example where the deceased was fleeing by car while exchanging fire with pursuing officers, killing one officer in the process. As such, using `fleeing` as a selection criteria requires caution, as the data is only clear in regard to the nature of `attack`. Mrinal's query is poor both in its lack of nuanced understanding of the variables but also because it is limited in scope. In order to correct these issues, we need to look at the relationships of the variables more holistically:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to aquire the total percentages of some of the pertinent variables:\n",
    "\n",
    "*Note*: Following code adaped from Guan, Y., (2020a) and Kartikaybhutani (alias) (2018), [geeksforgeeks.org](https://www.geeksforgeeks.org/python-pandas-series-nunique/#:~:text=Pandas%20nunique()%20is%20used,CSV%20file%20used%2C%20Click%20Here.&text=Return%20Type%3A%20Integer%20%E2%80%93%20Number%20of%20unique%20values%20in%20a%20column.&text=In%20this%20example%2C%20nunique(),unique%20values%20in%20Team%20column.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaped from Guan, Y., (2020a) and Kartikaybhutani (alias) (2018)\n",
    "df['armed'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_pie_plot(user_defined_df, title_str, values_str):\n",
    "    \"\"\" This function takes in a pd.DataFrame, a user defined title str, a user defined values string, \n",
    "    and then parses and produces a plotly express pie chart; it then returns the dataframe.\n",
    "\n",
    "    It is designed for use with the Washington Post dataset below:\n",
    "    The Washington Post -\n",
    "    https://www.washingtonpost.com/graphics/investigations/police-shootings-database/\n",
    "\n",
    "    It is designed for queries in the following format:\n",
    "    unarmed_alone = df[(df.armed =='unarmed')]\n",
    "\n",
    "    Adapted from or inspired by the following:\n",
    "    Mrinal, https://www.kaggle.com/mrinaal007/police-shootouts (defunct)\n",
    "    Dataquest Labs (2019),  https://www.dataquest.io/blog/excel-and-pandas/,\n",
    "    Guan. Y (2020a),\n",
    "    https://github.com/iSchool-590pr/Summer2020_examples/blob/master/week_08_pandas/pandas_intro.ipynb\n",
    "    Guan. Y (2020b),\n",
    "    https://github.com/iSchool-590pr/Summer2020_examples/blob/master/week_09_pandas2/pandas_pt2.ipyn\n",
    "    The Pandas Development Team (2020),\n",
    "    https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html\n",
    "    The Data Wrangling with pandas Cheat Sheet https://pandas.pydata.org/\n",
    "    and Weible, J (2020)\n",
    "\n",
    "    :param user_defined_df: pd.DataFrame\n",
    "    :param title_str: str\n",
    "    :param values_str: str\n",
    "    :return: pf.DataFrame\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import plotly.express as px\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    user_defined_df = user_defined_df[values_str].value_counts()\n",
    "    user_defined_df = pd.DataFrame(user_defined_df)\n",
    "    user_defined_df = user_defined_df.reset_index()\n",
    "    fig = px.pie(user_defined_df, values=values_str, names='index', \n",
    "                                  title= \"\\'\" + title_str + \"\\'\" + \" distribution by race\",\n",
    "                 color_discrete_sequence=px.colors.sequential.RdBu)\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "    return user_defined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "armed_distribution = df['armed'].value_counts(normalize=True)*100\n",
    "armed_distribution = pd.DataFrame(armed_distribution)\n",
    "armed_distribution = armed_distribution.reset_index()\n",
    "fig = px.pie(armed_distribution, values='armed', names='index', title=\"\\'armed\\' Weapon Distribution'\" ,  color_discrete_sequence=px.colors.sequential.RdBu)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "px_title = 'unarmed'\n",
    "px_value ='race'\n",
    "px_df = df[(df.armed == px_title)]\n",
    "\n",
    "unarmed_alone_df = generate_pie_plot(px_df, px_title, px_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px_title = 'armed'\n",
    "px_value ='race'\n",
    "px_df = df[(df.armed !='unarmed') & (df.armed !='undetermined')]\n",
    "\n",
    "not_unarmed_df = generate_pie_plot(px_df, px_title, px_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px_title = 'armed'\n",
    "px_value ='race'\n",
    "px_df = df[(df.armed !='unarmed') & (df.armed !='undetermined')]\n",
    "\n",
    "not_unarmed_df = generate_pie_plot(px_df, px_title, px_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weapon_undetermined = df[(df.armed =='undetermined')]\n",
    "weapon_undetermined = weapon_undetermined['race'].value_counts()\n",
    "weapon_undetermined = pd.DataFrame(weapon_undetermined)\n",
    "weapon_undetermined = weapon_undetermined.reset_index()\n",
    "fig = px.pie(weapon_undetermined, values='race', names='index', title=\"\\'unknown weapon'\\ distribution by race\", color_discrete_sequence=px.colors.sequential.RdBu)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaped from Guan, Y. (2020a) and Kartikaybhutani (alias) (2018)\n",
    "threat_distribution = df['threat_level'].nunique()\n",
    "threat_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the distribution of the `threat_level`. According to the distribution, it appears that ~2/3rds of the entries report the highest threat level, with 30% as some level of `other` threat, with the rest as `undetermined`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sources: (Pandey, P 2019), https://towardsdatascience.com/getting-more-value-from-the-pandas-value-counts-aa17230907a6) and Mrinaal007 (alias) (2020)\n",
    "threat_distribution = df['threat_level'].value_counts(normalize=True)*100\n",
    "threat_distribution = pd.DataFrame(threat_distribution)\n",
    "threat_distribution = threat_distribution.reset_index()\n",
    "fig = px.pie(threat_distribution, values='threat_level', names='index', title=\"\\'threat_level\\' Distribution'\" ,  color_discrete_sequence=px.colors.sequential.RdBu)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sources: (Pandey, P 2019), https://towardsdatascience.com/getting-more-value-from-the-pandas-value-counts-aa17230907a6) and Mrinaal007 (alias) (2020)\n",
    "flee_distribution = df['flee'].value_counts(normalize=True)*100\n",
    "flee_distribution = pd.DataFrame(flee_distribution)\n",
    "flee_distribution = flee_distribution.reset_index()\n",
    "fig = px.pie(flee_distribution, values='flee', names='index', title=\"\\'flee\\' Distribution'\" ,  color_discrete_sequence=px.colors.sequential.RdBu)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_usrus_dataframes(civilian_df, officer_df):\n",
    "    \"\"\"This function takes in two usrus dataframes and cleans the dataframes from the designated source,\n",
    "    creates a list of  those dataframes, and then returns that list.\n",
    "\n",
    "    Adapted from or inspired by the following:\n",
    "    Mrinal, https://www.kaggle.com/mrinaal007/police-shootouts (defunct)\n",
    "    Dataquest Labs (2019),  https://www.dataquest.io/blog/excel-and-pandas/,\n",
    "    Guan. Y (2020a),\n",
    "    https://github.com/iSchool-590pr/Summer2020_examples/blob/master/week_08_pandas/pandas_intro.ipynb\n",
    "    Guan. Y (2020b),\n",
    "    https://github.com/iSchool-590pr/Summer2020_examples/blob/master/week_09_pandas2/pandas_pt2.ipyn\n",
    "    The Pandas Development Team (2020),\n",
    "    https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html\n",
    "    The Data Wrangling with pandas Cheat Sheet https://pandas.pydata.org/\n",
    "    and Weible, J (2020)\n",
    "\n",
    "    :return: list of dataFrames\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    import pandas as pd # redundant?\n",
    "    import missingno as msno # redundant?\n",
    "\n",
    "    civilian_df.rename(\n",
    "        columns={'Included in Police Scorecard Analysis (All Incidents where Civilians were Shot '\n",
    "                 'At, '\n",
    "                 'Killed or Seriously Injured)?': 'included_in_scorecard'})\n",
    "    officer_df.rename(\n",
    "        columns={'Included in Police Scorecard Analysis (All Incidents where Civilians were Shot '\n",
    "                 'At, '\n",
    "                 'Killed or Seriously Injured)?': 'included_in_scorecard'})\n",
    "\n",
    "    # # check values\n",
    "    # print(civilian_df.dtypes)\n",
    "    # print(officer_df.dtypes)\n",
    "    # print(civilian_df.shape)\n",
    "    # print(officer_df.shape)\n",
    "\n",
    "    # # check head & tail\n",
    "    # print(civilian_df.head())\n",
    "    # print(civilian_df.tail())\n",
    "    # print(officer_df.head())\n",
    "    # print(officer_df.tail())\n",
    "\n",
    "\n",
    "    # # check handle missing data\n",
    "    # civilian_df.fillna(False)\n",
    "    # officer_df.fillna(False)\n",
    "\n",
    "\n",
    "    # concat a third combined df of both civillian and officer data, grouped by incident number\n",
    "    # Question:  this may be a memory hog\n",
    "\n",
    "\n",
    "    df_list = [civilian_df, officer_df]\n",
    "\n",
    "\n",
    "\n",
    "    return df_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# From (Sinyangwe, 2019) https://policescorecard.org/  and\n",
    "#  (The Pandas Development Team, 2020)https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html \n",
    "# Currently just exploring the data. \n",
    "# Adapted from Guan, Y. (2020a)\n",
    "usrus_xlsx_civ = pd.read_excel('URSUS Deadly Force Incident Data, 2016-2018.csv.xlsx',\n",
    "                               sheet_name='Use of Force Incident Data (URS',\n",
    "                               usecols=\"A:K, S:W,AC, AO\",\n",
    "                               dtype={ \"Injured\" : \"bool\",\n",
    "                               \"DISCHARGE_OF_FIREARM_INDIVIDUAL\":\"bool\",\n",
    "                                \"DISCHARGE_OF_FIREARM_INDIVIDUAL\":\"bool\",\n",
    "                                \"CIVILIAN_Assaulted_Officer\": \n",
    "                                \"bool\",\n",
    "                                \"CIVILIAN_Resisted\":\"bool\"},\n",
    "                                na_filter=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Adapted from (Guan, Y. 2020a)\n",
    "usrus_xlsx_off = pd.read_excel('URSUS Deadly Force Incident Data, 2016-2018.csv.xlsx',\n",
    "                                   sheet_name='Officers Involved',\n",
    "                                   usecols=\"A:K, S:W,AC, AO\",\n",
    "                                   dtype={\"Injured\": \"bool\",\n",
    "                                          \"DISCHARGE_OF_FIREARM_INDIVIDUAL\": \"bool\",\n",
    "                                          \"DISCHARGE_OF_FIREARM_INDIVIDUAL\": \"bool\",\n",
    "                                          \"CIVILIAN_Assaulted_Officer\":\n",
    "                                              \"bool\",\n",
    "                                          \"CIVILIAN_Resisted\": \"bool\"},\n",
    "                                   na_filter=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## *Fatal Force* Database Analysis\n",
    "\n",
    "The *Fatal Force* dataset is both extensive and detailed, and it is clearly a collection that its varied team has diligently and extensively curated. That it exists and that the public has been provided access to it for personal and proffesional analysis is a social good, and I am particular impressed by its inclusion of data relating to police body-worn cameras (BWC). \n",
    "Taken as a whole, it must be noted how, given the varied reporting practices from various departments and the tragically high number of police shootings that have occured in only a 5-year reporting period (5480), the dataset that The Post has compiled here is quite commendable. However, I believe there are issues with how they categorize race variables.    \n",
    "\n",
    "\n",
    "**Limitations of the *Fatal Force* Dataset**\n",
    "\n",
    "It is not a controversial statement to say the concept of race, is in itself, a highly nuanced issue; likewise, as the recent murder of George Floyd and the subsequent worldwide events that have followed that tragic event have readily shown, it is not a controversial statement to say that that the interplay between race and policing practices is highly nuanced and often contentious; the race's of the participants of any policing interation, both uniformed and citizen, likely play a role in that interaction's outcome, and it is regrettable that the *Fatal Force* database fails to provide a category about the race of the officer involved in the shootings it logs in order to help investigations further into that issue. Still, the dataset does provide a significant amount of information that promotes investigations into race, but I consider the categories to be inadequate in this regard, as the variables as written may leave too much open-ended racial data to be entirely reliable.\n",
    "\n",
    "That the included metadata is bare-bones is the issue with the database: it features very little documentation (the database itself is featured among ahost of web-based Post articles and ).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted previously, the Post's (2020) *Fatal Force* database features the following categories:\n",
    "\n",
    "* W: White, non-Hispanic\n",
    "* B: Black, non-Hispanic\n",
    "* A: Asian\n",
    "* N: Native American\n",
    "* H: Hispanic\n",
    "* O: Other\n",
    "* None: unknown\n",
    "\n",
    "While one understands there are sacrfices and limitations that must be made when deciding how to compile data, these racial categories are not ideal. \n",
    "For one, the racial categories here are both overly-broad and too narrow (or at least ambigious):\n",
    "\n",
    "What, perhaps constitues the *Other* variable? Neither the database's metadata nor the related Post article answers this question.\n",
    "- Do these categories include mixed-race, bi-racial, or multi-racial individuals?\n",
    "- Do Pacific Islanders fall under this category, as well? Or do they fall under the broad and vague category *Asian*?\n",
    "- Are all those of Middle-Eastern descent also considered *Other*s? \n",
    "- Do those of Brazilian background also classify as *Other* here (as Brazil is a Portuguese-speaking nation, this background does not typically classify as \"Hispanic\")? \n",
    "\n",
    "Similarly, as Mrinal's *4. Missing Values* check found earlier, nearly 10 percent of the *race* data was missing.\n",
    "\n",
    "*Note: The following code is adapted from* (Guan, 2020) *and* (mrinaal007 (alias), 2020)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Adapted from Guan, Y (2020a), https://github.com/iSchool-590pr/Summer2020_examples/blob/master/week_08_pandas/pandas_intro.ipynb  \n",
    "other_count = df[df['race']=='O'].shape[0]\n",
    "df_copy = pd.read_csv('fatal-police-shootings-data.csv') # Create a second df still containing NAs to check their count\n",
    "none_count = df_copy['race'].isna().sum() # adapted from (mrinaal007 (alias), 2020).\n",
    "print(\"The dataset contains\", other_count, \"\\\"Other\\\" entries, and\", none_count, \"\\\"None\\\" entries (i.e., \", other_count + none_count,\") out of 5480 total entries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Admittedly, 43 \"Other\" entries is minimal, but when it is paired with another 546 missing entries the total is a not insignificant amount of data. \n",
    "Mrinal focused on analyzing 4 sections grouped by race data, and race-centric shooting analysis was also a primary feature of the Post article associated with this dataset (Tate et al., 2020). There is a strong intrest in race-based analysis right now, but (as corroborated by Mrinal's value check) ~10%, of the data is unclear to that discussion. I consider that a sizable enough a portion of missing data to render the findings suspect. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, there is another ambiguity issue with using these racial categories: strictly speaking, \"Hispanic\" is not a *race*, but an *ethnic identity*, and has officially been excluded from the 2020 United States Census as a potential racial category choice. This race/ethnic group designation is itself contentious amoung those who make up its membership, however, with a majority of Hispanics considering it to be a racial background, according to a 2015 article from the Pew Research Center (Gonzalez-Barrera & Lopez):        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename='screenshots/Pew.race.PNG')) # Adapted from (Mathieu, 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(CONSIDER CUTTING)\n",
    "\n",
    "In practical reality, whether members of the Hispanic community consider said background to also be their racial identity varies by individual (I, for one, consider myself bi-racial, including Hispanic), but using this particular data format both codefies troubling implications for those using the database along with also placing the Post's reporting at odds with itself. Writing for an 2019 Washington Post article entitled *Five myths about Hispanics*, Bowie State University professor of Language, Literature, and Cultural Studies Horacio Sierra noted the following:\n",
    "\n",
    ">Hispanics constitute an ethnic community, not a race — a distinction evident on forms that ask if you’re non-Hispanic white or non-Hispanic black...Seeing Hispanics as a racial group erases our diversity and discounts the racism and pigmentocracy that plague Hispanic societies. To ask Afro-Hispanics to choose between being black and being Hispanic is to negate their unique identity. To ask white Hispanics to distance themselves from their European heritage is to diminish the important ways Spain helped shape the United States... Hispanics can look like anyone. Such differences require more nuance than we get when we consolidate Hispanics into one race (para 3). \n",
    "\n",
    "Whether Sierra's view is the definitive or correct view is on this subject is debatable, but it is certainly informed and highlights a potenial bias that has been built into the dataset distributed by the same outfit that published his article.* If the Post's fatal encounter database is the largest public database of its kind (as the Post claims), then any codified bias could have ongoing implications in any analysis derived from its use in the future. ~Moreover, as the murder of George Floyd has revealed the harm race-based policing policing practices have caused black Americans, it does cause one to wonder what the data analysis would change (if at all) were the coded categories did not create such a strict delineation between Hispanic and non-Hispanic, especially in regards to Afro-Hispanics (who have been frequently overlooked in most discussions around Hispanics).~ #MAYBE CUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(NOTE lack of data from Puerto Rico, Guam, A. Samoa, and lack of metadata clarity over Native American territory policing and Federal policing data, time allowing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- (Dataquest Labs, 2019; Sinyangwe, 2019; The Pandas Development Team, 2020)\n",
    "\n",
    "- Bar Charts | Python | Plotly. (2020). Plotly. https://plotly.com/python/bar-charts/\n",
    "\n",
    "- Data Wrangling with pandas Cheat Sheet. (n.d.). Retrieved August 7, 2020, from http://pandas.pydata.org\n",
    "\n",
    "- Dataquest Labs, I. (2019, June 13). Excel Tutorial for Python and Pandas – Dataquest. Dataquest. https://www.dataquest.io/blog/excel-and-pandas/\n",
    "\n",
    "- Gonzalez-Barrera, A., & Lopez, M. H. (2015, June 15). Is being Hispanic a matter of race, ethnicity or both? | Pew Research Center. Pew Research Center. https://www.pewresearch.org/fact-tank/\n",
    "2015/06/15/is-being-hispanic-a-matter-of-race-ethnicity-or-both/\n",
    "\n",
    "- Guan, Y. (2020a, July 7). pandas_intro.ipynb. GitHub. https://github.com/iSchool-590pr/Summer2020_examples/blob/master/week_08_pandas/pandas_intro.ipynb\n",
    "\n",
    "- Guan, Y. (2020b, July 14). Week 8 - Pandas, part 2. GitHub. https://github.com/iSchool-590pr/Summer2020_examples/blob/master/week_09_pandas2/pandas_pt2.ipynb\n",
    "\n",
    "- Hunter, J., Dale, D., Droettboom, M., & Matplot Development Team. (2020, July 17). Pyplot tutorial — Matplotlib 3.3.0 documentation. https://matplotlib.org/tutorials/introductory/pyplot.html\n",
    "\n",
    "- Jenkins, J., Rich, S., Tate, J., Muyskens, J., Fox, J., Fallis, D., & Rindler, D. (2020, July 8). Police shootings database 2015-2020 - Washington Post. Washington Post. https://\n",
    "www.washingtonpost.com/graphics/investigations/police-shootings-database/\n",
    "\n",
    "- Mathieu, O. (2017). Image in markdown do not display in jupyter notebooks (#33995) · Issues · GitLab.org / GitLab FOSS · GitLab. GitLab.Org. https://gitlab.com/gitlab-org/gitlab-foss/-/\n",
    "issues/33995\n",
    "\n",
    "- mrinaal007 (alias). (2020). Police Shootouts. Kaggle. https://www.kaggle.com/mrinaal007\n",
    "\n",
    "- NetworkX Developers. (2019, October 17). Tutorial — NetworkX 2.4 documentation. NetworkX. https://networkx.github.io/documentation/stable/tutorial.html#edges\n",
    "\n",
    "- Pandey, P. (2019, October 22). Getting more value from the Pandas’ value_counts() . Towards Data Science. https://towardsdatascience.com/\n",
    "getting-more-value-from-the-pandas-value-counts-aa17230907a6\n",
    "\n",
    "- Samoshin, A. (2020, June). Data Police shootings | Kaggle. https://www.kaggle.com/mrmorj/data-police-shootings/notebooks?sortBy=hotness&group=everyone&pageSize=20&datasetId=723010\n",
    "\n",
    "- Sierra, H. (2019, October 3). Five myths about Hispanics - The Washington Post. Washington Post. https://www.washingtonpost.com/\n",
    "\n",
    "- Sinyangwe, S. (2019). California Police Scorecard. Campaign Zero. https://policescorecard.org/\n",
    "\n",
    "- Tate, J., Jenkins, J., Rich, S., Muyskens, J., Kennedy Elliott, & Mellnik, T. (2015). GitHub - washingtonpost/data-police-shootings: The Washington Post is compiling a database of every fatal - shooting in the United States by a police officer in the line of duty in 2015 and 2016. The Washington Post. https://github.com/washingtonpost/data-police-shootings\n",
    "\n",
    "- The Constitution of the United States and The Declaration of Independence. (2016). Racehorse Publishing.\n",
    "\n",
    "- The Pandas Development Team. (2020, July 28). pandas.read_excel — pandas 1.1.0 documentation. Pandas. https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html\n",
    "\n",
    "- Weible, J. (2020). Program Quality and Code Reviews. https://learn.illinois.edu/pluginfile.php/6279486/mod_resource/content/2/Program Quality and Code Reviews.pdf\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
